import requests  
from requests.exceptions import RequestException  
from multiprocessing import Pool  
import re  
import json  
  
def get_one_page(url):  
    try:  
        response = requests.get(url)  
        if response.status_code == 200:  
            return response.text  
        return None  
    except RequestException:  
        return None  
def parse_one_page(html):  
    pattern = re.compile('<dd>.*?board-index.*?">(.*?)</i>.*?<img.*?data-src="(.*?)".*?name"><a.*?>(.*?)</a>.*?star">(.*?)</p>.*?releasetime">(.*?)</p>.*?integer">(.*?)</i>.*?fraction">(.*?)</i>.*?</dd>',re.S)  
    items = re.findall(pattern,html)  
    for item in items:  
        yield {  
            '排名':item[0],  
            '链接':item[1],  
            '电影名':item[2],  
            '演员':item[3].strip()[3:],  
            '时间':item[4].strip()[5:],  
            '分数':item[5]+item[6]  
  
        }  
  
def write_file(content):  
    with open('maoyan.txt','a',encoding='utf-8') as f:  
        f.write(json.dumps(content,ensure_ascii=False) + '\n')  
  
def main(i):  
        url = 'http://maoyan.com/board/4?offset=' + str(i)  
        html = get_one_page(url)  
        for item in parse_one_page(html):  
            print(item)  
            write_file(item)  
  
if __name__ == '__main__':  
    pool = Pool()  
    pool.map(main,[i*10 for i in range(10)])  
